{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build_a_food_image_classifier_Light_Heavy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI4KfZ4UWh6m"
      },
      "source": [
        "# Challenge 1: Classification\n",
        "In this challenge, you're given a food classification dataset which has 101 classes. You need to analyze and preprocess the dataset as well as build deep learning models for performing food classification. \n",
        "<br>\n",
        "Three models are to be trained for this task, mainly light, medium, and heavy model. <br>\n",
        "Examples: <br>\n",
        "Light model - mobilenetv2 <br>\n",
        "Medium model - Resnet50 <br>\n",
        "Heavy model - VGG19 <br>\n",
        "<br>\n",
        "The above given models are examples. You are free to choose any deep learning model to train. \n",
        "\n",
        "**Main Objective**:\n",
        "You are supposed to use both TensorFlow and PyTorch for this task. You need to train one model for each framework. (You can use one of the frameworks again for the third model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceDtYK4bjjgm"
      },
      "source": [
        "## Summary \n",
        "\n",
        "Create a table for your train and test accuracy as well as speed for each model (mention the framework used for training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3wks2WO1RWu"
      },
      "source": [
        "# Analyze the dataset\n",
        "## Objectives\n",
        "1. Upload the dataset provided (Google Drive link). \n",
        "2. Extract the dataset. \n",
        "3. Re-arrange dataset into training and testing folders. \n",
        "4. List number of samples in training and testing folders. \n",
        "5. Plot sample images from training and testing datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RiAa6ZBygBC",
        "outputId": "0e1efe79-e442-4e6d-93e1-cb97e565f1c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdnHKl0L-Rj"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBV0H_0ojS9E"
      },
      "source": [
        "### Your Response/Notes\n",
        "\n",
        "You can summarize your work for this section here/give any explanations if required. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeJAJWCsWHz-"
      },
      "source": [
        "# Extract the dataset\n",
        "!unzip /content/drive/MyDrive/food-101.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ1nN2I7Gabj"
      },
      "source": [
        "**Re-arranging dataset into folders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Dm-9ekGZmo"
      },
      "source": [
        "# Function to re-arrange the dataset\n",
        "def prepare_data(filepath, src, dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pevXDG6gKKvM"
      },
      "source": [
        "# create training data\n",
        "prepare_data('/content/food-101/meta/train.txt','/content/food-101/images','/content/train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-lj8VgULFIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df6374e-74f1-45b1-f80c-fc7aa34c40f2"
      },
      "source": [
        "n_samples = [len(os.listdir(os.path.join('/content/train', folder))) for folder in os.listdir('/content/train')]\n",
        "print(\"Total number of samples in train folder:\", sum(n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder: 75750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HAFZzM6KvOK"
      },
      "source": [
        "# create testing data\n",
        "prepare_data('/content/food-101/meta/test.txt','/content/food-101/images','/content/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ6WIQhoLKEG"
      },
      "source": [
        "n_samples = [len(os.listdir(os.path.join('/content/test', folder))) for folder in os.listdir('/content/test')]\n",
        "print(\"Total number of samples in test folder:\", sum(n_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "748E41E84wBy"
      },
      "source": [
        "# Pre-process Images\n",
        "## Objectives\n",
        "1. Implement preprocessing codes for each model. \n",
        "2. Augment the dataset. \n",
        "3. Preview the preprocessed dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AvwdT0UjgYV"
      },
      "source": [
        "### Your Response/Notes\n",
        "\n",
        "You can summarize your work for this section here/give any explanations if required. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGbHvkMTXfaP"
      },
      "source": [
        "### Preprocessing steps for light model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ2RNTQMXj1-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzuvEl_2jp0U"
      },
      "source": [
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (160, 160)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fCtJkpwj5Mw",
        "outputId": "f258cfc3-bab6-4948-a620-fc985c13a143"
      },
      "source": [
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75750 files belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAoRUls1kOg7",
        "outputId": "72244707-7b38-45b6-ea7e-561028551658"
      },
      "source": [
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                            shuffle=True,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25250 files belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WGI9y8PklxY",
        "outputId": "50478618-a4c4-499d-c15e-89f9e3bd2530"
      },
      "source": [
        "print(\"Number of train batches: %d\" % tf.data.experimental.cardinality(train_dataset))\n",
        "print(\"Number of test batches: %d\" % tf.data.experimental.cardinality(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train batches: 1184\n",
            "Number of test batches: 395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TocGhc7BlxDW"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCly8QS0l9_R"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  #tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation((-0.2,0.2)),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(.2, .2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QzJM0W3l-Ge"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_GwMQJ_l-Kq"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "print(image_batch.shape)\n",
        "print(label_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4fa1vTXkU6"
      },
      "source": [
        "### Preprocessing steps for medium model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDF_pj-tCFLF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-v7d26uXqpF"
      },
      "source": [
        "### Preprocessing steps for heavier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxMzHpGGYGQ1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNe--ER1YGQ2"
      },
      "source": [
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (299, 299)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i7RVlLcYGQ2",
        "outputId": "70e625c6-694f-455a-c7a0-d9534f3d38c5"
      },
      "source": [
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75750 files belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evl8w27LYGQ3",
        "outputId": "f5ab19b5-33dd-4d2d-e07e-0670be333a46"
      },
      "source": [
        "test_dataset = image_dataset_from_directory(test_dir,\n",
        "                                            shuffle=True,\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25250 files belonging to 101 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BED4iOmoYGQ3",
        "outputId": "6a2d771a-8f4a-4852-8a0a-cc86ff45f214"
      },
      "source": [
        "print(\"Number of train batches: %d\" % tf.data.experimental.cardinality(train_dataset))\n",
        "print(\"Number of test batches: %d\" % tf.data.experimental.cardinality(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train batches: 1184\n",
            "Number of test batches: 395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHrqbiVzYGQ3"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99-tGlXBYGQ4"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  #tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation((-0.2,0.2)),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(.2, .2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk8-WpvEYGQ4"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.InceptionResNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe5W4w-yMJaN"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roRTiCw6YGQ4"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "print(image_batch.shape)\n",
        "print(label_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xfjwj8nz9ZT"
      },
      "source": [
        "# Training different models\n",
        "## Objectives\n",
        "1. Obtain 90% accuracy in all the models trained. \n",
        "2. You're free to use any techniques for traning such as transfer learning, knowledge transfer, etc. \n",
        "3. The models should not overfit the training dataset. \n",
        "4. Measure the performance in terms of accuracy and speed of each model. \n",
        "5. Visualize the training and testing performance using TensorBoard. \n",
        "\n",
        "#### Optional:\n",
        "1. Apply weight quantization to increase the speed of the models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9kG6B-ajhuP"
      },
      "source": [
        "### Your Response/Notes\n",
        "\n",
        "1. Light Model - Fine Tuning on MobileNetv2 used. Unfreezed the layers after 100 and trained the MobileNetv2 network.\n",
        "\n",
        "2. Medium Model - Trained by transfer learning on ResNet50 base model for the first few epochs (25). After this unfreezed all the layers of the base model and uploaded the weights saved in the transfer learning step and continued fine tuning the model.\n",
        "\n",
        "3. Heavy Model - Followed the same method transfer learning first on the base model i.e., InceptionResNetV2 and then fine tuning using the weights from transfer learning step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjIQN4X83P33"
      },
      "source": [
        "## Train Light model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkN3sNnPevbe"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntewH7rNOyZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc00057a-c99d-49eb-f0e1-790ddbe10f3a"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peL1IpivuKyi",
        "outputId": "f1ce1f8e-1b6a-4d03-eac9-d91129153dde"
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(101, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd_jSkICNBGU"
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZg8i_MSNCMz",
        "outputId": "aa7db331-9214-404b-a754-d775b020611b"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIO9HeUquVtB"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZJ5DtHGufVM"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW7SRz0Mu0Ng"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoGBdsipP-Q-"
      },
      "source": [
        "# Loading weights from Transfer Learning model, to get pretrained weights of the last FC layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z59YioVdOAJy"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/model_light_tl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcrrFEXEPywG"
      },
      "source": [
        "log_addr = '/content/drive/MyDrive/'\n",
        "csv_logger = CSVLogger(log_addr+\"model_light_logs_ft.csv\", append=True, separator=';')\n",
        "model_checkpoint = ModelCheckpoint(log_addr+'model_light_ft.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, mode=\"min\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBhJtQSPPywJ"
      },
      "source": [
        "from datetime import datetime\n",
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcotudLEvHTc"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=60,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[csv_logger,model_checkpoint,early_stopping,reduce_lr,tboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRBJr1nxToGM"
      },
      "source": [
        "model.save('/content/drive/MyDrive/model_light.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOgQE3lg0X46"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ejlyny0fYI"
      },
      "source": [
        "%tensorboard --logdir=logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qZktckAGB2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5bf7f0-a94e-47d5-b2ea-729dfa9da636"
      },
      "source": [
        "#### Inference\n",
        "import time\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/model_light.h5')\n",
        "start = time.time()\n",
        "model.predict(test_dataset, steps=395)\n",
        "end = time.time()\n",
        "print(\"Time taken: \", end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken:  48.252076148986816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfAq5BUpxZGm"
      },
      "source": [
        "## Train Medium model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0KO9QuBoLJ"
      },
      "source": [
        "#### Inference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4_m8n3ZENLZ"
      },
      "source": [
        "# Import necessary PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyqLNJdUEOEq"
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.RandomRotation(45),\n",
        "                                       transforms.RandomAffine(45),\n",
        "                                       transforms.ColorJitter(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# Use 10-crop for Test Time Augmentation\n",
        "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "                                      #transforms.TenCrop(224),\n",
        "                                      #transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                      #transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])(crop) for crop in crops]))])\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(\"/content/train\", transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(\"/content/test\", transform=test_transforms)\n",
        "\n",
        "# Using the image datasets and the tranforms, define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size= 64, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYdKFtGEOSm"
      },
      "source": [
        "# Load the Final saved model\n",
        "checkpoint = torch.load(\"/content/drive/My Drive/resnet50model.pth\", map_location='cpu')\n",
        "\n",
        "model = models.resnet50(pretrained=False)\n",
        "\n",
        "classifier = nn.Linear(2048, 101)\n",
        "model.fc = classifier\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state'], strict=False)\n",
        "\n",
        "# specify loss function (categorical cross-entropy) same as used earlier\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WYNpHblF8j7"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvzRU4G9Enj6"
      },
      "source": [
        "\n",
        "# Create list of class names\n",
        "with open('food-101/meta/classes.txt', 'r') as txt:\n",
        "    classes = [l.strip() for l in txt.readlines()]\n",
        "\n",
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(len(classes)))\n",
        "class_total = list(0. for i in range(len(classes)))\n",
        "\n",
        "start = time.time()\n",
        "#move model to gpu\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# iterate over test data\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "      ## For 10-crop Testing\n",
        "      print(data.size())\n",
        "      bs, c, h, w = data.size()\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model(data.view(-1, c, h, w))\n",
        "      #output = temp_output.view(bs, -1).mean(1)\n",
        "      # calculate the batch loss\n",
        "      #loss = criterion(output, target)\n",
        "      # update average test loss \n",
        "      #test_loss += loss.item()*data.size(0)\n",
        "      # convert output probabilities to predicted class\n",
        "      _, pred = torch.max(output, 1)    \n",
        "      # compare predictions to true label\n",
        "      correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "      correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "      # calculate test accuracy for each object class\n",
        "      for i in range(len(target)):\n",
        "          label = target.data[i]\n",
        "          class_correct[label] += correct[i].item()\n",
        "          class_total[label] += 1\n",
        "    \n",
        "# average test loss\n",
        "#test_loss = test_loss/len(test_loader.dataset)\n",
        "#print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "'''\n",
        "for i in range(len(classes)):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %.2f%% (%2d/%2d)' % (classes[i], 100 * class_correct[i] / class_total[i],\n",
        "                                                         np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "'''\n",
        "print('\\nTest Accuracy (Overall): %.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total),\n",
        "                                                      np.sum(class_correct), np.sum(class_total)))\n",
        "end=time.time()\n",
        "print('Time taken: ', end-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_cga_PWJoAk"
      },
      "source": [
        "## Train heavy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FysEJNFa9l4"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3W0vPQ8YhxS",
        "outputId": "b214540b-43fb-4bbf-c043-7fae08752bef"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1536)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzY1ya__YhxT",
        "outputId": "668aef6e-9dc1-41e1-980d-ea0bdbd4db9a"
      },
      "source": [
        "fc_layer = tf.keras.layers.Dense(512, activation='relu')\n",
        "prediction_layer = tf.keras.layers.Dense(101, activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0QcEojUiQS1"
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XojOD4GtYhxU"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "#x = fc_layer(x)\n",
        "#x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR0PPN8OiZyO"
      },
      "source": [
        "# Using the pre-trained weight for last FC layer from Transfer Learning\n",
        "model.load_weights('/content/drive/MyDrive/model_heavy.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjxj3Iznallb"
      },
      "source": [
        "log_addr = '/content/drive/MyDrive/'\n",
        "csv_logger = CSVLogger(log_addr+\"model_heavy_logs_ft3.csv\", append=True, separator=';')\n",
        "model_checkpoint = ModelCheckpoint(log_addr+'model_heavy_ft3.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, mode=\"min\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7WvrNSz9615"
      },
      "source": [
        "from datetime import datetime\n",
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1Ux4TlYhxU"
      },
      "source": [
        "base_learning_rate = 0.00005\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8y9kIFYhxU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkHRHxemYhxU"
      },
      "source": [
        "history_lr2 = model.fit(train_dataset,\n",
        "                    epochs=60,\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks = [model_checkpoint, early_stopping, csv_logger, reduce_lr, tboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0tKYhy6_jbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3231875-60f9-4048-ef5a-2dd480115b73"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68UZFougAQgw"
      },
      "source": [
        "%tensorboard --logdir=logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsrgaO1DYhxV"
      },
      "source": [
        "model.save('/content/drive/MyDrive/model_light.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCSboE0_kor",
        "outputId": "6b6aab20-8a52-48cf-a06b-156c21237004"
      },
      "source": [
        "#### Inference\n",
        "import time\n",
        "start = time.time()\n",
        "y_pred = model.predict(test_dataset, steps=395)\n",
        "end = time.time()\n",
        "print('Time taken:', end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken: 131.5124113559723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6kzKyC7Hym"
      },
      "source": [
        "### Summary\n",
        "\n",
        "| Type  | Model | Framework   | Training Acc | Training Loss | Test Acc | Test Loss | Speed |\n",
        "|-------|-------|-------------|--------------|---------------|---------|-----------|-------|\n",
        "|Light  | MobileNetv2 | Tensorflow  | 0.7819       | 0.7617        | 0.7204   | 1.0571    | 48.25 s    |\n",
        "|Medium| ResNet50| PyTorch     | 0.8462       | 0.5685        | 0.8615   | 0.5290    | 198.30 s    |\n",
        "|Heavy| InceptionResNetv2 | Tensorflow  | 0.9131       | 0.2933        | 0.8516   | 0.5660    | 131.51 s    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg2-uNbqAu49"
      },
      "source": [
        "Please note:\n",
        "1. In the column \"Speed\", we have calculalted inference time on test dataaset, i.e., time taken to predict for 25250 images.\n",
        "2. Heavy model shows a faster inference time due to tf.data pipelining, which reduces the GPU idle time significantly and hence producs a better inference time. For a ResNet50 model trained using tensorflow, our inference time will be faster than the Heavy model.\n",
        "3. The notebook for Medium model i.e., ResNet50 implemented in PyTorch will be different. In this notebook we have run only inference for the PyTorch trained model.\n",
        "4. The Heavy model could be tuned further, but it takes a long time to train and I did not have any GPU available.\n",
        "5. The outputs in the cells do not correspond to the best scenario results achieved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmpot5hADp1z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}